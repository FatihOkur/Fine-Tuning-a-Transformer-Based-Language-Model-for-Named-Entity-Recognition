{"activation": "gelu", "architectures": ["DistilBertForTokenClassification"], "attention_dropout": 0.1, "dim": 768, "dropout": 0.1, "dtype": "float32", "hidden_dim": 3072, "id2label": {"0": "B-art", "1": "B-cur", "2": "B-geo", "3": "B-gpe", "4": "B-org", "5": "B-per", "6": "B-tim", "7": "I-art", "8": "I-cur", "9": "I-geo", "10": "I-gpe", "11": "I-org", "12": "I-per", "13": "I-tim", "14": "O"}, "initializer_range": 0.02, "label2id": {"B-art": 0, "B-cur": 1, "B-geo": 2, "B-gpe": 3, "B-org": 4, "B-per": 5, "B-tim": 6, "I-art": 7, "I-cur": 8, "I-geo": 9, "I-gpe": 10, "I-org": 11, "I-per": 12, "I-tim": 13, "O": 14}, "max_position_embeddings": 512, "model_type": "distilbert", "n_heads": 12, "n_layers": 6, "pad_token_id": 0, "qa_dropout": 0.1, "seq_classif_dropout": 0.2, "sinusoidal_pos_embds": false, "tie_weights_": true, "transformers_version": "4.57.3", "vocab_size": 30522}